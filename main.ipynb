{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ZhoFzWm1bYDL",
        "outputId": "2b6daaf9-1918-4eeb-d964-965875b1a010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "  Downloading anvil_uplink-0.5.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting argparse (from anvil-uplink)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from anvil-uplink) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from anvil-uplink) (1.17.0)\n",
            "Collecting ws4py-sslupdate (from anvil-uplink)\n",
            "  Downloading ws4py_sslupdate-0.5.1b0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading anvil_uplink-0.5.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading ws4py_sslupdate-0.5.1b0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ws4py-sslupdate, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.5.2 argparse-1.4.0 ws4py-sslupdate-0.5.1b0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2f614ebf19024f7ea866d2c2c7f7e737",
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install anvil-uplink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObgfKskjwG7m"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "from uagents import Agent, Context, Model\n",
        "import os\n",
        "from groq import Groq\n",
        "\n",
        "# Apply nest_asyncio to avoid event loop conflicts\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Define the message model\n",
        "class BudgetQuery(Model):\n",
        "    query: str\n",
        "\n",
        "# Define the agent\n",
        "budget_agent = Agent(name=\"BudgetAssistant\")\n",
        "\n",
        "# Queue to store agent responses\n",
        "agent_output_queue = asyncio.Queue()\n",
        "\n",
        "@budget_agent.on_message(model=BudgetQuery)\n",
        "async def handle_message(ctx: Context, message: BudgetQuery):\n",
        "    key = os.getenv(\"GROQ_API_KEY\")  # Ensure API key is stored in environment variables\n",
        "    client = Groq(api_key=key)\n",
        "\n",
        "    similar_chunks = vector_store.similarity_search(message.query, n_results=5)\n",
        "    context = \"\\n\".join([chunk.content for chunk in similar_chunks])\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the context and the query which is to be answered using the context:\\n{context}\\n\\nNow, {message.query}\"},\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "    )\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    await agent_output_queue.put(response)  # Store response in the queue\n",
        "    ctx.send(response)\n",
        "\n",
        "async def get_budget_response(query):\n",
        "    message = BudgetQuery(query=query)\n",
        "    await budget_agent.put(message)  # Send message to agent\n",
        "    return await agent_output_queue.get()  # Wait for response\n",
        "\n",
        "async def main():\n",
        "    asyncio.create_task(budget_agent.run_async())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A00Xnma4bb5z"
      },
      "outputs": [],
      "source": [
        "import anvil.server\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "import re\n",
        "import anvil.server\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1SpEIf9bhRm",
        "outputId": "aaf3d965-db19-43dd-a4ea-b52aa6dc3e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ],
      "source": [
        "anvil.server.disconnect()\n",
        "anvil.server.connect(\"INSERT YOUR ANVIL SERVER KEY HERE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NHwfulLvbj0r"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import anvil.server\n",
        "\n",
        "@anvil.server.callable\n",
        "def orc(text):\n",
        "\n",
        "    print(f\"Received text: {text}\")\n",
        "    classified = OrchestrationAgent(text)\n",
        "    print(f\"Classified as: {classified}\")\n",
        "\n",
        "    response_data = {\"classification\": classified, \"response\": \"\", \"extra_info\": \"\"}\n",
        "\n",
        "    if classified == \"BudgetBreakDownAgent\":\n",
        "        response = BudgetBreakDownAgent(text)\n",
        "        print(f\"Budget Breakdown Response: {response}\")\n",
        "\n",
        "        # GraphPlottingAgent(response)\n",
        "        items = CategoryWiseBreakdownAgent(response)\n",
        "        print(f\"Category Breakdown Items: {items}\")\n",
        "\n",
        "        if items:\n",
        "            button = items[0]\n",
        "            CategoryAnalysis = CategoryBudgetAnalysisAgent(button)\n",
        "            print(f\"Category Analysis: {CategoryAnalysis}\")\n",
        "            return CategoryAnalysis\n",
        "            response_data[\"response\"] = str(CategoryAnalysis)\n",
        "        else:\n",
        "            return response\n",
        "            response_data[\"response\"] = str(response)\n",
        "\n",
        "    elif classified == \"EssentialExpenditureAgent\":\n",
        "        response = EssentialExpenditureAgent(text)\n",
        "        print(f\"Essential Expenditure Response: {response}\")\n",
        "        return response\n",
        "\n",
        "        GraphPlottingAgent(response)\n",
        "        response1 = FinancialAdvisorAgent(response)\n",
        "        print(f\"Financial Advisor Response: {response1}\")\n",
        "        # GraphPlottingAgent(response1)\n",
        "        return response1\n",
        "\n",
        "        response_data[\"response\"] = str(response1)\n",
        "\n",
        "    elif classified == \"FinancialPlanningAgent\":\n",
        "        response = EssentialExpenditureAgent(text)\n",
        "        response1 = FinancialAdvisorAgent(response)\n",
        "        response2 = FinancialPlanningAgent(text, response1)\n",
        "\n",
        "        print(f\"Financial Planning Response: {response2}\")\n",
        "        return response2\n",
        "\n",
        "        # GraphPlottingAgent(response2)\n",
        "\n",
        "        response_data[\"response\"] = str(response2)\n",
        "\n",
        "    else:\n",
        "        response_data[\"response\"] = \"Invalid Classification\"\n",
        "\n",
        "    # Convert to JSON string for better readability in Anvil’s text box\n",
        "    json_string=json.dumps(response_data, indent=4)\n",
        "\n",
        "    return 'Invalid Classification'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@anvil.server.callable\n",
        "def generate_graph(context, graph_type=\"auto\"):\n",
        "    \"\"\"\n",
        "    Generate a graph visualization based on financial data in the context.\n",
        "\n",
        "    Args:\n",
        "        context (str): Text containing financial information\n",
        "        graph_type (str): Type of graph ('bar', 'pie', 'line', or 'auto')\n",
        "\n",
        "    Returns:\n",
        "        str: Base64 encoded image for Anvil image placeholder\n",
        "    \"\"\"\n",
        "    # Extract financial data from the context\n",
        "    expenses = extract_financial_data(context)\n",
        "\n",
        "    if not expenses:\n",
        "        return create_error_graph(\"No financial data found in the provided context\")\n",
        "\n",
        "    # Determine best graph type if set to auto\n",
        "    if graph_type == \"auto\":\n",
        "        if \"month\" in context.lower() or \"monthly\" in context.lower():\n",
        "            graph_type = \"bar\" if len(expenses) > 6 else \"pie\"\n",
        "        elif \"category\" in context.lower():\n",
        "            graph_type = \"pie\"\n",
        "        elif \"trend\" in context.lower() or \"over time\" in context.lower():\n",
        "            graph_type = \"line\"\n",
        "        else:\n",
        "            graph_type = \"bar\" if len(expenses) > 5 else \"pie\"\n",
        "\n",
        "    # Create appropriate visualization\n",
        "    if graph_type == \"pie\":\n",
        "        return create_pie_chart(expenses)\n",
        "    elif graph_type == \"line\":\n",
        "        return create_line_chart(expenses)\n",
        "    else:  # Default to bar\n",
        "        return create_bar_chart(expenses)\n",
        "\n",
        "def extract_financial_data(context):\n",
        "    \"\"\"Extract financial data from context string\"\"\"\n",
        "    expenses = {}\n",
        "\n",
        "    # Look for common expense patterns in financial text\n",
        "    # Pattern for category and amount (e.g., \"Groceries: $250\")\n",
        "    category_pattern = r'([A-Za-z\\s&]+):\\s*\\$?(\\d+,?\\d*(?:\\.\\d+)?)'\n",
        "    matches = re.findall(category_pattern, context)\n",
        "\n",
        "    for category, amount in matches:\n",
        "        category = category.strip()\n",
        "        # Convert amount string to float, handling commas\n",
        "        amount_value = float(amount.replace(',', ''))\n",
        "        if category in expenses:\n",
        "            expenses[category] += amount_value\n",
        "        else:\n",
        "            expenses[category] = amount_value\n",
        "\n",
        "    # If no matches found, try simpler pattern\n",
        "    if not expenses:\n",
        "        lines = context.split('\\n')\n",
        "        for line in lines:\n",
        "            # Look for lines with dollar amounts\n",
        "            amount_match = re.search(r'\\$(\\d+,?\\d*(?:\\.\\d+)?)', line)\n",
        "            if amount_match:\n",
        "                amount = float(amount_match.group(1).replace(',', ''))\n",
        "                # Extract category (text before the amount)\n",
        "                category_match = re.search(r'^([A-Za-z\\s&]+)', line)\n",
        "                if category_match:\n",
        "                    category = category_match.group(1).strip()\n",
        "                    if len(category) > 2 and category.lower() not in ['total', 'sum']:\n",
        "                        expenses[category] = amount\n",
        "\n",
        "    return expenses\n",
        "\n",
        "\n",
        "@anvil.server.callable\n",
        "def generate_secondary_graph(context, graph_type=\"auto\"):\n",
        "    \"\"\"\n",
        "    Generate a secondary graph visualization that's different from the primary one.\n",
        "\n",
        "    Args:\n",
        "        context (str): Text containing financial information\n",
        "        primary_graph_type (str): Type of the primary graph ('bar', 'pie', 'line')\n",
        "\n",
        "    Returns:\n",
        "        str: Base64 encoded image for Anvil image placeholder\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    expenses = extract_financial_data(context)\n",
        "\n",
        "    if graph_type == \"auto\":\n",
        "        if \"month\" in context.lower() or \"monthly\" in context.lower():\n",
        "            graph_type = \"bar\" if len(expenses) > 6 else \"pie\"\n",
        "        elif \"category\" in context.lower():\n",
        "            graph_type = \"pie\"\n",
        "        elif \"trend\" in context.lower() or \"over time\" in context.lower():\n",
        "            graph_type = \"line\"\n",
        "        else:\n",
        "            graph_type = \"bar\" if len(expenses) > 5 else \"pie\"\n",
        "    primary_graph_type = graph_type\n",
        "    # Extract financial data from the context\n",
        "\n",
        "\n",
        "    if not expenses:\n",
        "        return create_error_graph(\"No financial data found in the provided context\")\n",
        "\n",
        "    # Determine secondary graph type that complements the primary\n",
        "    if primary_graph_type == \"pie\":\n",
        "        # If primary is pie, show bar or line for different perspective\n",
        "        if \"trend\" in context.lower() or \"over time\" in context.lower():\n",
        "            secondary_type = \"line\"\n",
        "        else:\n",
        "            secondary_type = \"bar\"\n",
        "    elif primary_graph_type == \"bar\":\n",
        "        # If primary is bar, show pie or stacked bar\n",
        "        if len(expenses) <= 8:\n",
        "            secondary_type = \"pie\"\n",
        "        else:\n",
        "            secondary_type = \"stacked_bar\"\n",
        "    elif primary_graph_type == \"line\":\n",
        "        # If primary is line, show bar or area chart\n",
        "        secondary_type = \"bar\"\n",
        "    else:\n",
        "        # Default fallback\n",
        "        secondary_type = \"pie\" if primary_graph_type == \"bar\" else \"bar\"\n",
        "\n",
        "    # Create appropriate visualization\n",
        "    if secondary_type == \"pie\":\n",
        "        return create_pie_chart(expenses)\n",
        "    elif secondary_type == \"line\":\n",
        "        return create_line_chart(expenses)\n",
        "    elif secondary_type == \"stacked_bar\":\n",
        "        return create_stacked_bar_chart(expenses)\n",
        "    else:  # Default to bar\n",
        "        return create_bar_chart(expenses)\n",
        "\n",
        "def create_stacked_bar_chart(data):\n",
        "    \"\"\"Create a stacked bar chart showing spending levels\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    categories = list(data.keys())\n",
        "    values = list(data.values())\n",
        "\n",
        "    # Define spending levels (low, medium, high)\n",
        "    max_val = max(values)\n",
        "    high_thresh = max_val * 0.6\n",
        "    medium_thresh = max_val * 0.3\n",
        "\n",
        "    # Create stacked bars\n",
        "    low = [min(v, medium_thresh) for v in values]\n",
        "    medium = [min(max(v - medium_thresh, 0), high_thresh - medium_thresh) for v in values]\n",
        "    high = [max(v - high_thresh, 0) for v in values]\n",
        "\n",
        "    plt.bar(categories, low, color='lightgreen', label='Low')\n",
        "    plt.bar(categories, medium, bottom=low, color='gold', label='Medium')\n",
        "    plt.bar(categories, high, bottom=[l+m for l,m in zip(low, medium)], color='salmon', label='High')\n",
        "\n",
        "    plt.xlabel('Category')\n",
        "    plt.ylabel('Amount ($)')\n",
        "    plt.title('Spending by Level')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig_to_base64()\n",
        "\n",
        "def create_bar_chart(data):\n",
        "    \"\"\"Create a bar chart from the data\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(data.keys(), data.values(), color='skyblue')\n",
        "    plt.xlabel('Category')\n",
        "    plt.ylabel('Amount ($)')\n",
        "    plt.title('Expense Breakdown')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                f'${int(height)}', ha='center', va='bottom')\n",
        "\n",
        "    return fig_to_base64()\n",
        "\n",
        "def create_pie_chart(data):\n",
        "    \"\"\"Create a pie chart from the data\"\"\"\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    wedges, texts, autotexts = plt.pie(\n",
        "        data.values(),\n",
        "        labels=data.keys(),\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=90,\n",
        "        shadow=True\n",
        "    )\n",
        "\n",
        "    # Improve text readability\n",
        "    for text in texts:\n",
        "        text.set_fontsize(9)\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_fontsize(9)\n",
        "        autotext.set_color('white')\n",
        "\n",
        "    plt.axis('equal')\n",
        "    plt.title('Expense Distribution')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig_to_base64()\n",
        "\n",
        "def create_line_chart(data):\n",
        "    \"\"\"Create a line chart showing trends\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(list(data.keys()), list(data.values()), marker='o', linestyle='-', color='blue')\n",
        "    plt.xlabel('Category/Period')\n",
        "    plt.ylabel('Amount ($)')\n",
        "    plt.title('Expense Trend')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Add value labels\n",
        "    for i, val in enumerate(data.values()):\n",
        "        plt.text(i, val + max(data.values())*0.02, f'${int(val)}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig_to_base64()\n",
        "\n",
        "def create_error_graph(message):\n",
        "    \"\"\"Create a simple graph with an error message\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.text(0.5, 0.5, message, ha='center', va='center', fontsize=14)\n",
        "    plt.axis('off')\n",
        "    return fig_to_base64()\n",
        "\n",
        "def fig_to_base64():\n",
        "    \"\"\"Convert matplotlib figure to base64 string for Anvil\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=100)\n",
        "    buf.seek(0)\n",
        "    img_str = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
        "    plt.close()\n",
        "    return img_str\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "snCF4VGD3Seg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NOo1GOHTbr7T",
        "outputId": "5a6b7a33-3508-4378-c666-45ff69d425f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.20.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.1/526.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "bigframes 1.41.0 requires sqlglot>=23.6.3, but you have sqlglot 10.6.1 which is incompatible.\n",
            "ibis-framework 9.5.0 requires sqlglot<25.21,>=23.4, but you have sqlglot 10.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "\n",
        "!pip install -qU langchain-community pathway pyngrok sentence_transformers unstructured unstructured[pdf] pdfplumber pymupdf Pillow pandas tiktoken llm-app\n",
        "\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReDXvCFRbQEl",
        "outputId": "80b6a1e1-3204-4807-a233-bb2e80703986"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.e5042dce39060cc34bc223455f25cf1d26db4655.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "import pickle\n",
        "import os\n",
        "import pathway as pw\n",
        "# from pathway.xpacks.llm.vector_store   import VectorStoreServer\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "import faiss\n",
        "from pyngrok import ngrok\n",
        "\n",
        "@dataclass\n",
        "class Document:\n",
        "    id: str\n",
        "    content: str\n",
        "    metadata: Optional[Dict] = None\n",
        "\n",
        "@dataclass\n",
        "class Chunk:\n",
        "    id: str\n",
        "    doc_id: str\n",
        "    content: str\n",
        "    vector: np.ndarray = None\n",
        "    metadata: Optional[Dict] = None\n",
        "\n",
        "class EnhancedVectorStore:\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_model: str = \"nomic-ai/nomic-embed-text-v1\",\n",
        "        chunk_size: int = 500,\n",
        "        host: str = \"127.0.0.1\",\n",
        "        port: int = 8668,\n",
        "        base_path: str = \"vector_db\",\n",
        "        cache_dir: str = \"./Cache\",\n",
        "        license_key: str = None\n",
        "    ):\n",
        "        self.embedding_model = embedding_model\n",
        "        self.chunk_size = chunk_size\n",
        "        self.host = host\n",
        "        self.port = port\n",
        "        self.base_path = base_path\n",
        "        self.cache_dir = cache_dir\n",
        "\n",
        "        if license_key:\n",
        "            pw.set_license_key(license_key)\n",
        "\n",
        "        self.embeddings = SentenceTransformerEmbeddings(\n",
        "            model_name=embedding_model,\n",
        "            model_kwargs={\"trust_remote_code\": True}\n",
        "        )\n",
        "        self.text_splitter = CharacterTextSplitter(chunk_size=chunk_size)\n",
        "\n",
        "        os.makedirs(base_path, exist_ok=True)\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "    def process_documents(self, documents: List[Document]) -> List[Chunk]:\n",
        "        \"\"\"Process documents into chunks with embeddings.\"\"\"\n",
        "        chunks = []\n",
        "        for doc in documents:\n",
        "            texts = self.text_splitter.split_text(doc.content)\n",
        "            for i, text in enumerate(texts):\n",
        "                chunk = Chunk(\n",
        "                    id=f\"{doc.id}chunk{i}\",\n",
        "                    doc_id=doc.id,\n",
        "                    content=text,\n",
        "                    metadata=doc.metadata\n",
        "                )\n",
        "                chunk.vector = self.embeddings.embed_query(text)\n",
        "                chunks.append(chunk)\n",
        "        return chunks\n",
        "\n",
        "    def store_chunks(self, chunks: List[Chunk]):\n",
        "        \"\"\"Store chunks directly in the vector database using FAISS.\"\"\"\n",
        "        # Check if chunks is empty before accessing elements\n",
        "        if not chunks:\n",
        "            print(\"No chunks to store.\")\n",
        "            return\n",
        "\n",
        "        index = faiss.IndexFlatL2(len(chunks[0].vector))\n",
        "        vectors = np.array([chunk.vector for chunk in chunks])\n",
        "        index.add(vectors)\n",
        "\n",
        "        db_path = os.path.join(self.base_path, \"chunks_db.index\")\n",
        "        faiss.write_index(index, db_path)\n",
        "\n",
        "        chunk_metadata = {chunk.id: chunk for chunk in chunks}\n",
        "        with open(os.path.join(self.base_path, \"chunks_metadata.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(chunk_metadata, f)\n",
        "\n",
        "    def similarity_search(self, query: str, n_results: int = 5) -> List[Chunk]:\n",
        "        \"\"\"Perform similarity search directly on chunks.\"\"\"\n",
        "        query_vector = self.embeddings.embed_query(query)\n",
        "        db_path = os.path.join(self.base_path, \"chunks_db.index\")\n",
        "        index = faiss.read_index(db_path)\n",
        "\n",
        "        with open(os.path.join(self.base_path, \"chunks_metadata.pkl\"), \"rb\") as f:\n",
        "            chunk_metadata = pickle.load(f)\n",
        "\n",
        "        D, I = index.search(np.array([query_vector]), n_results)\n",
        "        results = [chunk_metadata[list(chunk_metadata.keys())[idx]] for idx in I[0]]\n",
        "        return results\n",
        "\n",
        "def run_server(self):\n",
        "        \"\"\"Run a Pathway web server to accept query and context dynamically.\"\"\"\n",
        "        webserver = pw.io.http.PathwayWebserver(host=self.host, port=self.port, with_cors=True)\n",
        "\n",
        "        def serve(route, schema, handler, documentation):\n",
        "            queries, writer = pw.io.http.rest_connector(\n",
        "                webserver=webserver,\n",
        "                route=route,\n",
        "                methods=(\"POST\",),\n",
        "                schema=schema,\n",
        "                autocommit_duration_ms=50,\n",
        "                delete_completed_queries=False,\n",
        "                documentation=documentation,\n",
        "            )\n",
        "            writer(handler(queries))\n",
        "\n",
        "        class QuerySchema(pw.Schema):\n",
        "            query: str\n",
        "            context: str\n",
        "\n",
        "        def process_query(queries):\n",
        "            \"\"\"Process user query and store context before retrieving results.\"\"\"\n",
        "            for query in queries:\n",
        "                context_doc = Document(id=f\"ctx_{query['query']}\", content=query['context'])\n",
        "                chunks = self.process_documents([context_doc])\n",
        "                self.store_chunks(chunks)\n",
        "                return self.similarity_search(query['query'])\n",
        "\n",
        "        serve(\n",
        "            \"/v1/retrieve\",\n",
        "            QuerySchema,\n",
        "            process_query,\n",
        "            pw.io.http.EndpointDocumentation(\n",
        "                summary=\"Store context and retrieve similar documents\",\n",
        "                description=\"Stores provided context in vector store and retrieves similar documents based on query.\",\n",
        "                method_types=(\"POST\",),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        webserver._run()\n",
        "\n",
        "vector_store = EnhancedVectorStore()\n",
        "documents = [\n",
        "    Document(id=\"doc1\", content=\"01-Feb-2025, Rent, 8000\"),\n",
        "    Document(id=\"doc2\", content=\"02-Feb-2025, Groceries, 2500\"),\n",
        "    Document(id=\"doc3\", content=\"03-Feb-2025, Electricity Bill, 1200\"),\n",
        "    Document(id=\"doc4\", content=\"04-Feb-2025, Internet Bill, 800\"),\n",
        "    Document(id=\"doc5\", content=\"05-Feb-2025, Transportation, 1500\"),\n",
        "    Document(id=\"doc6\", content=\"06-March-2025, Dining Out, 900\"),\n",
        "    Document(id=\"doc7\", content=\"07-Feb-2025, Mobile Recharge, 500\"),\n",
        "    Document(id=\"doc8\", content=\"08-March-2025, Gym Membership, 2000\"),\n",
        "    Document(id=\"doc9\", content=\"09-Feb-2025, Stationery, 400\"),\n",
        "    Document(id=\"doc10\", content=\"10-March-2025, Movie Ticket, 600\"),\n",
        "    Document(id=\"doc11\", content=\"11-Feb-2025, Medicines, 1100\"),\n",
        "    Document(id=\"doc12\", content=\"12-April-2025, Books, 1800\"),\n",
        "    Document(id=\"doc13\", content=\"13-April-2025, Subscription Services, 1200\"),\n",
        "    Document(id=\"doc14\", content=\"14-Feb-2025, Valentine's Gift, 2500\"),\n",
        "    Document(id=\"doc15\", content=\"15-March-2025, Travel, 3000\"),\n",
        "    Document(id=\"doc16\", content=\"16-Feb-2025, Groceries, 2200\"),\n",
        "    Document(id=\"doc17\", content=\"17-Feb-2025, Car Fuel, 2800\"),\n",
        "    Document(id=\"doc18\", content=\"18-Feb-2025, Home Maintenance, 1500\"),\n",
        "    Document(id=\"doc19\", content=\"19-March-2025, Clothing, 3500\"),\n",
        "    Document(id=\"doc20\", content=\"20-Feb-2025, Coffee, 300\"),\n",
        "]\n",
        "\n",
        "chunks = vector_store.process_documents(documents)\n",
        "vector_store.store_chunks(chunks)\n",
        "\n",
        "\n",
        "key = \"INSERT YOUR GROK API KEY HERE\"\n",
        "\n",
        "import os\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=key,\n",
        ")\n",
        "# def BudgetBreakDownAgent(query):\n",
        "#   # query = \"Give a detailed description of my budget expenses in the month of March.\"\n",
        "#   similar_chunks = vector_store.similarity_search(query, n_results=5)\n",
        "\n",
        "#   context = \"\\n\".join([chunk.content for chunk in similar_chunks])\n",
        "\n",
        "#   chat_completion = client.chat.completions.create(\n",
        "#       messages=[\n",
        "#           {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "#           {\"role\": \"user\", \"content\": f\"Here are is the context and the query which is to be answered using the context:\\n{context}\\n\\nNow, {query}.\"},\n",
        "#       ],\n",
        "#       model=\"llama-3.3-70b-versatile\",\n",
        "#   )\n",
        "\n",
        "#   response = chat_completion.choices[0].message.content\n",
        "#   return response\n",
        "import subprocess\n",
        "\n",
        "def BudgetBreakDownAgent(query):\n",
        "    # Run the external script\n",
        "    subprocess.run([\"python\", \"/content/budget_breakdown.py\", query])\n",
        "\n",
        "    # Read the generated response\n",
        "    with open(\"/content/budget_summary.txt\", \"r\") as f:\n",
        "        response = f.read()\n",
        "    print(response)\n",
        "\n",
        "    return str(response)\n",
        "\n",
        "\n",
        "\n",
        "def GraphPlottingAgent(context):\n",
        "  # query1 = response\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a data visualization assistant specializing in financial data representation. Generate a bar graph or a pie chart to visualise the data provided in the query\"},\n",
        "          {\"role\": \"user\", \"content\": f\"Generate a interactive and beautiful Python code to visualize the following financial data. Do not provide any description of the code generated, output should be only the code:\\n\\n{context}\"},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  code = chat_completion.choices[0].message.content\n",
        "  code = code.lstrip(\"python\")\n",
        "  code = code.rstrip(\"\")\n",
        "  exec(code, globals())\n",
        "\n",
        "def CategoryWiseBreakdownAgent(context):\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a financial advisor agent providing a list of items on which user has major expenditure.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"Given a context input:\\n{context}, return a list of items of which there is major expenditure for the user. Output format:PYTHON LIST. Do not give any explanation or description\"},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  items = chat_completion.choices[0].message.content\n",
        "  # items = CategoryWiseBreakdownAgent(response)\n",
        "  items = items.lstrip(\"python\")\n",
        "  items = items.rstrip(\"\")\n",
        "\n",
        "  return items\n",
        "\n",
        "button = 'Clothing'\n",
        "\n",
        "def CategoryBudgetAnalysisAgent(button):\n",
        "  query111 = f'Give a detailed description of my budget expenses in {button}.'\n",
        "  similar_chunks = vector_store.similarity_search(query111, n_results=5)\n",
        "\n",
        "  context = \"\\n\".join([chunk.content for chunk in similar_chunks])\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"Here are is the context and the query which is to be answered using the context:\\n{context}\\n\\nNow, {button}\"},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  response111 = chat_completion.choices[0].message.content\n",
        "  return response111\n",
        "\n",
        "\n",
        "def EssentialExpenditureAgent(query):\n",
        "  # query112 = f'Give a detailed description of essential and non-essential expenditures for the month of February.'\n",
        "  similar_chunks = vector_store.similarity_search(query, n_results=5)\n",
        "\n",
        "  context = \"\\n\".join([chunk.content for chunk in similar_chunks])\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"Here are is the context and the query which is to be answered using the context:\\n{context}\\n\\nNow, {query}. Give a detailed breakdown of essential and non-essential expenditures for the user.\"},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  response112 = chat_completion.choices[0].message.content\n",
        "  return response112\n",
        "\n",
        "\n",
        "def FinancialAdvisorAgent(context):\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "          {\"role\": \"user\", \"content\": f'Given context{context}, give a detailed analysis of how can user improve their money saving, do cost-cuttings and improve budget. Also give a monthly or yearly estimate for how much can be saved by better finances'},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  response113 = chat_completion.choices[0].message.content\n",
        "  return response113\n",
        "\n",
        "def FinancialPlanningAgent(query, context):\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are a financial assistant providing detailed budget summaries based on user data.\"},\n",
        "          {\"role\": \"user\", \"content\": f' You are given a context input {context} and a query {query}, give an estimate to the question, if the user does not improve their budget, and if the user improve their budget. Also give a analysis of the query.'},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  responselt = chat_completion.choices[0].message.content\n",
        "  return responselt\n",
        "\n",
        "\n",
        "def OrchestrationAgent(query):\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": \"You are an orchestration agent whose task is to classify queries.\"},\n",
        "          {\"role\": \"user\", \"content\": f\"\"\"Given user query{query}, classify what does the query ask for from one of the following categories:\n",
        "          # BudgetBreakDownAgent -- Monthly/yearly/category wise breakdown of budget\n",
        "          # EssentialExpenditureAgent - Breakdown and analysis of essential and non-essential expenditures\n",
        "          # FinancialPlanningAgent - Estimate for time needed to achieve a long-term or short-term goal.\n",
        "          Output format: No explanantion, only a single word answer giving output of the agent to which query was classified to.\"\"\"},\n",
        "      ],\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "  response = chat_completion.choices[0].message.content\n",
        "  return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lUtpY0Ddba0O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tiR-aabW0d",
        "outputId": "c3426f98-dd62-4670-da1a-335a39ad3c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received text: can i buy a car\n",
            "Classified as: FinancialPlanningAgent\n",
            "Financial Planning Response: **Analysis of the Query:**\n",
            "\n",
            "The user is considering purchasing a car, and we need to assess whether they can afford it based on their current financial situation and potential future savings. To estimate the feasibility of buying a car, we'll consider the user's current expenses, potential savings, and the costs associated with owning a car.\n",
            "\n",
            "**Current Financial Situation:**\n",
            "\n",
            "* Total Monthly Expenditure: 11500\n",
            "* Essential Expenditures: 9000\n",
            "* Non-Essential Expenditures: 2500\n",
            "\n",
            "**Estimated Car Expenses:**\n",
            "\n",
            "* Vehicle purchase price: Assume a moderate-priced car costing around 200,000 (this can vary greatly depending on the location, make, and model)\n",
            "* Monthly car loan payment: Approximately 2500-3500 per month (assuming a 5-year loan with an interest rate of 5-7%)\n",
            "* Insurance: 1000-2000 per year (approximately 80-170 per month)\n",
            "* Fuel: 2800 per month (as mentioned in the original data, but this may decrease with a more fuel-efficient vehicle)\n",
            "* Maintenance: 500-1000 per month (depending on the vehicle's age, make, and model)\n",
            "\n",
            "**If the user does not improve their budget:**\n",
            "\n",
            "* The user's current essential expenditures are 9000, and they spend 2500 on non-essential items.\n",
            "* Adding the estimated car loan payment (2500-3500) would increase their monthly expenses by approximately 28-39%.\n",
            "* Considering the additional costs of insurance, fuel, and maintenance, the user's total monthly expenses would increase by around 50-70%.\n",
            "* Given their current financial situation, it may be challenging for the user to afford the added expenses of owning a car without making significant adjustments to their budget.\n",
            "\n",
            "**Estimated savings needed to afford a car:**\n",
            "\n",
            "* Assuming the user wants to allocate 20-30% of their income towards car expenses, they would need to increase their income or reduce their expenses to accommodate the additional costs.\n",
            "* Based on their current expenses, the user would need to save around 3000-5000 per month to afford the car expenses, which is a significant increase from their current non-essential expenditure of 2500.\n",
            "\n",
            "**If the user improves their budget:**\n",
            "\n",
            "* By implementing the suggested cost-cutting measures, the user can potentially save 2200-4500 per month.\n",
            "* This amount can be allocated towards car expenses, reducing the financial burden of owning a car.\n",
            "* With the estimated monthly savings, the user may be able to afford the car loan payment, insurance, fuel, and maintenance costs.\n",
            "* However, it's essential to note that the user should prioritize building an emergency fund, paying off high-interest debt, and investing in long-term financial goals before allocating a significant portion of their income towards car expenses.\n",
            "\n",
            "**Recommendations:**\n",
            "\n",
            "1. **Review and adjust the budget:** Before purchasing a car, the user should review their budget and make adjustments to ensure they can afford the added expenses.\n",
            "2. **Prioritize needs over wants:** The user should prioritize essential expenses over non-essential expenses and consider delaying the car purchase until they have a more stable financial foundation.\n",
            "3. **Consider alternative options:** The user may want to explore alternative transportation options, such as carpooling, using public transport, or buying a more fuel-efficient vehicle, to reduce their expenses.\n",
            "4. **Build an emergency fund:** The user should focus on building an emergency fund to cover 3-6 months of living expenses before taking on the additional costs of owning a car.\n",
            "\n",
            "In conclusion, if the user does not improve their budget, it may be challenging for them to afford the expenses associated with owning a car. However, if they implement the suggested cost-cutting measures and allocate their savings effectively, they may be able to afford the car expenses. It's essential for the user to prioritize their financial goals, build an emergency fund, and review their budget before making a significant purchase like a car.\n",
            "Received text: give me a detailed breakdown of my expenses in march\n",
            "Classified as: BudgetBreakDownAgent\n",
            "Received text: give me a detailed breakdown of my expenditure in march\n",
            "Classified as: BudgetBreakDownAgent\n",
            "Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "You have recorded a total of 3 expenses in the month of March. \n",
            "\n",
            "1. The most recent expense was on 19th March, where you spent ₹3500 on Clothing. \n",
            "2. Prior to that, on 15th March, you incurred an expense of ₹3000 for Travel purposes.\n",
            "3. The earliest recorded expense in March was on 6th March, where you spent ₹900 on Dining Out.\n",
            "\n",
            "In terms of categorization, your expenses can be broken down as follows:\n",
            "- Clothing: ₹3500 (41.18% of total expenses)\n",
            "- Travel: ₹3000 (35.29% of total expenses)\n",
            "- Dining Out: ₹900 (10.59% of total expenses)\n",
            "\n",
            "The total expenses for the month of March amount to ₹7400. \n",
            "\n",
            "Please note that this analysis is based on the limited data provided and may not reflect your complete financial situation for the month of March.\n",
            "Budget Breakdown Response: Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "You have recorded a total of 3 expenses in the month of March. \n",
            "\n",
            "1. The most recent expense was on 19th March, where you spent ₹3500 on Clothing. \n",
            "2. Prior to that, on 15th March, you incurred an expense of ₹3000 for Travel purposes.\n",
            "3. The earliest recorded expense in March was on 6th March, where you spent ₹900 on Dining Out.\n",
            "\n",
            "In terms of categorization, your expenses can be broken down as follows:\n",
            "- Clothing: ₹3500 (41.18% of total expenses)\n",
            "- Travel: ₹3000 (35.29% of total expenses)\n",
            "- Dining Out: ₹900 (10.59% of total expenses)\n",
            "\n",
            "The total expenses for the month of March amount to ₹7400. \n",
            "\n",
            "Please note that this analysis is based on the limited data provided and may not reflect your complete financial situation for the month of March.\n",
            "Category Breakdown Items: ['Clothing', 'Travel']\n",
            "Category Analysis: It seems like you've provided a list of expenses with dates and categories. To provide a detailed budget summary, I'll break down the expenses by category and calculate the total spent in each category.\n",
            "\n",
            "1. Electricity Bill: 1200 (one transaction)\n",
            "2. Groceries: 4700 (two transactions: 2500 on 02-Feb-2025 and 2200 on 16-Feb-2025)\n",
            "3. Stationery: 400 (one transaction)\n",
            "4. Subscription Services: 1200 (one transaction)\n",
            "\n",
            "Total spent: 1200 + 4700 + 400 + 1200 = 7500\n",
            "\n",
            "Please let me know what specific question you have regarding this data, such as the total spent in a particular month or the average spent per category. I'll do my best to provide a helpful response.\n",
            "Received text: give me a detailed breakdown of my spendings in march\n",
            "Classified as: BudgetBreakDownAgent\n",
            "Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "In the month of March, you have incurred expenses in three categories: Clothing, Travel, and Dining Out. \n",
            "\n",
            "1. Clothing: On 19th March 2025, you spent ₹3500 on clothing. This is your only expense in the clothing category for the month.\n",
            "\n",
            "2. Travel: On 15th March 2025, you spent ₹3000 on travel. This is your only expense in the travel category for the month.\n",
            "\n",
            "3. Dining Out: On 6th March 2025, you spent ₹900 on dining out. This is your only expense in the dining out category for the month.\n",
            "\n",
            "Total expenses for the month of March: ₹3500 (Clothing) + ₹3000 (Travel) + ₹900 (Dining Out) = ₹7400.\n",
            "\n",
            "It appears that the majority of your expenses in March were divided between clothing and travel, which together account for approximately 86% of your total expenses (₹3500 + ₹3000 = ₹6500). The remaining 14% (₹900) was spent on dining out.\n",
            "Budget Breakdown Response: Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "In the month of March, you have incurred expenses in three categories: Clothing, Travel, and Dining Out. \n",
            "\n",
            "1. Clothing: On 19th March 2025, you spent ₹3500 on clothing. This is your only expense in the clothing category for the month.\n",
            "\n",
            "2. Travel: On 15th March 2025, you spent ₹3000 on travel. This is your only expense in the travel category for the month.\n",
            "\n",
            "3. Dining Out: On 6th March 2025, you spent ₹900 on dining out. This is your only expense in the dining out category for the month.\n",
            "\n",
            "Total expenses for the month of March: ₹3500 (Clothing) + ₹3000 (Travel) + ₹900 (Dining Out) = ₹7400.\n",
            "\n",
            "It appears that the majority of your expenses in March were divided between clothing and travel, which together account for approximately 86% of your total expenses (₹3500 + ₹3000 = ₹6500). The remaining 14% (₹900) was spent on dining out.\n",
            "Category Breakdown Items: ['Clothing', 'Travel']\n",
            "Category Analysis: It seems like you provided a list of expenses, but you didn't complete your query. Please go ahead and ask your question about these expenses, such as \"What is the total spent on groceries?\" or \"What is the total expenditure for the month of February?\" and I'll be happy to help.\n",
            "Received text: give me a detailed breakdown of my spendings in the month of march\n",
            "Classified as: BudgetBreakDownAgent\n",
            "Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "In the month of March, you have incurred expenses in three categories: Clothing, Travel, and Dining Out. \n",
            "\n",
            "1. Clothing: On 19th March 2025, you spent ₹3500 on clothing. This is your only expense in the clothing category for the month.\n",
            "\n",
            "2. Travel: On 15th March 2025, you spent ₹3000 on travel. This is your only expense in the travel category for the month.\n",
            "\n",
            "3. Dining Out: On 6th March 2025, you spent ₹900 on dining out. This is your only expense in the dining out category for the month.\n",
            "\n",
            "Total expenses for the month of March: ₹3500 (Clothing) + ₹3000 (Travel) + ₹900 (Dining Out) = ₹7400.\n",
            "\n",
            "It appears that the majority of your expenses in March were divided between clothing and travel, which together account for approximately 86% of your total expenses (₹3500 + ₹3000 = ₹6500). The remaining 14% (₹900) was spent on dining out.\n",
            "Budget Breakdown Response: Based on the provided data, here is a detailed description of your budget expenses in the month of March:\n",
            "\n",
            "In the month of March, you have incurred expenses in three categories: Clothing, Travel, and Dining Out. \n",
            "\n",
            "1. Clothing: On 19th March 2025, you spent ₹3500 on clothing. This is your only expense in the clothing category for the month.\n",
            "\n",
            "2. Travel: On 15th March 2025, you spent ₹3000 on travel. This is your only expense in the travel category for the month.\n",
            "\n",
            "3. Dining Out: On 6th March 2025, you spent ₹900 on dining out. This is your only expense in the dining out category for the month.\n",
            "\n",
            "Total expenses for the month of March: ₹3500 (Clothing) + ₹3000 (Travel) + ₹900 (Dining Out) = ₹7400.\n",
            "\n",
            "It appears that the majority of your expenses in March were divided between clothing and travel, which together account for approximately 86% of your total expenses (₹3500 + ₹3000 = ₹6500). The remaining 14% (₹900) was spent on dining out.\n",
            "Category Breakdown Items: ```python\n",
            "['Clothing', 'Travel']\n",
            "```\n",
            "Category Analysis: It seems like you've provided a list of expenses with dates and amounts. To provide a detailed budget summary, I'll categorize and calculate the total expenses.\n",
            "\n",
            "Here's the summary:\n",
            "\n",
            "1. Electricity Bill: 1200 (03-Feb-2025)\n",
            "2. Stationery: 400 (09-Feb-2025)\n",
            "3. Groceries: \n",
            "   - 2500 (02-Feb-2025)\n",
            "   - 2200 (16-Feb-2025)\n",
            "   Total Groceries: 4700\n",
            "4. Internet Bill: 800 (04-Feb-2025)\n",
            "\n",
            "Total expenses: 1200 + 400 + 4700 + 800 = 7100\n",
            "\n",
            "Please let me know what specific query you have regarding this data, and I'll be happy to assist you.\n",
            "Received text: Give me detailed information about my spendings in march\n",
            "Classified as: BudgetBreakDownAgent\n",
            "Based on the provided data, here is a detailed description of your budget expenses for the month of March:\n",
            "\n",
            "**Total Expenses:** ₹8,400\n",
            "\n",
            "**Expense Breakdown:**\n",
            "\n",
            "1. **Clothing:** ₹3,500 (41.67% of total expenses) - This expense was incurred on 19th March 2025.\n",
            "2. **Travel:** ₹3,000 (35.71% of total expenses) - This expense was incurred on 15th March 2025.\n",
            "3. **Dining Out:** ₹900 (10.71% of total expenses) - This expense was incurred on 6th March 2025.\n",
            "\n",
            "**Summary:** In the month of March, your expenses were primarily dominated by Clothing and Travel, which together account for approximately 77.38% of your total expenses. Dining Out expenses constitute a relatively smaller portion of your overall expenditure.\n",
            "Budget Breakdown Response: Based on the provided data, here is a detailed description of your budget expenses for the month of March:\n",
            "\n",
            "**Total Expenses:** ₹8,400\n",
            "\n",
            "**Expense Breakdown:**\n",
            "\n",
            "1. **Clothing:** ₹3,500 (41.67% of total expenses) - This expense was incurred on 19th March 2025.\n",
            "2. **Travel:** ₹3,000 (35.71% of total expenses) - This expense was incurred on 15th March 2025.\n",
            "3. **Dining Out:** ₹900 (10.71% of total expenses) - This expense was incurred on 6th March 2025.\n",
            "\n",
            "**Summary:** In the month of March, your expenses were primarily dominated by Clothing and Travel, which together account for approximately 77.38% of your total expenses. Dining Out expenses constitute a relatively smaller portion of your overall expenditure.\n",
            "Category Breakdown Items: ['Clothing', 'Travel']\n",
            "Category Analysis: It seems like you provided a list of expenses, but your question got cut off. Please complete your question, and I'll be happy to help you with a detailed budget summary based on the provided data.\n",
            "\n",
            "From what I can see, the expenses are:\n",
            "\n",
            "- Electricity Bill: 1200 (03-Feb-2025)\n",
            "- Groceries: 2200 (16-Feb-2025) and 2500 (02-Feb-2025) = Total Groceries: 4700\n",
            "- Stationery: 400 (09-Feb-2025)\n",
            "- Subscription Services: 1200 (13-April-2025)\n",
            "\n",
            "Total expenses so far: 1200 + 4700 + 400 + 1200 = 7500\n",
            "\n",
            "Please go ahead and ask your question, and I'll provide a more detailed analysis.\n"
          ]
        }
      ],
      "source": [
        "anvil.server.wait_forever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cb5tL4jBlttN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
